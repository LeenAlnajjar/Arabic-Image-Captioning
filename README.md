# Arabic-Image-Captioning
The concept of the project is to generate Arabic captions from the Arabic Flickr8K dataset, the tools that were used are the pre-trained CNN (MobileNet-V2) and the LSTM model, in addition to a set of steps using the NLP. The aim of the project is to create a solid ground and very initial steps in order to help children with learning difficulties. 
# Abstract
The process of generating content from images is considered to be a very difficult and challenging task, but at the same time, it is very impressive because it helps blind people to have a better understanding of their surroundings. The importance of automatic image caption generator for children with learning difficulties come from the visibility of transferring the captions later on to voice by using text-to-speech technology in order to describe the whole image for those people. Although it is considered a critical mission, the resources and projects regarding automatic Arabic image captioning are rare and need further improvements. According to that, this work aims to build an Automated Arabic Image Caption Generator model to give a short explanation of the images in the Arabic language. The model will be constructed from both CNN which aims to figure out features from figures and the LSTM which will take the features from the CNN and provide suitable descriptions for these features.  The data itself is constructed from images and text or description for each image.
# Data source
